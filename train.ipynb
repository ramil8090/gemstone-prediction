{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTs6RfUNh610"
      },
      "source": [
        "## Note\n",
        "The easiest and fastest way to train a neural network is to use Google Colab. Just load this `train.ipynb` notebook to Google Colab, then switch to a T4 GPU and execute all cells. It will take approximately 10 minutes to complete the training and export the best-trained model to ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YfBf-D9ZazR4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import glob\n",
        "import shutil\n",
        "import zipfile\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N54V02S2f2vM",
        "outputId": "0d1b209b-2241-45da-d8de-9824bf5b9906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting onnx>=1.16 (from onnxscript)\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx_ir, onnxscript\n",
            "Successfully installed onnx-1.20.0 onnx_ir-0.1.13 onnxscript-0.5.7\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTMmyWsBbAcl",
        "outputId": "41792224-6122-4e26-9137-5a349e48e879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy==2.0.2\n",
            "pytorch==2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "print(f'numpy=={np.__version__}')\n",
        "print(f'pytorch=={torch.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m0xxsu_AbFZ0"
      },
      "outputs": [],
      "source": [
        "# ImageNet normalization values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wNdBF_k1bLis"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "scK5AZPubNY0"
      },
      "outputs": [],
      "source": [
        "# Training transforms WITH augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomRotation(10),           # Rotate up to 10 degrees\n",
        "    transforms.RandomResizedCrop(256, scale=(0.9, 1.0)),  # Zoom\n",
        "    transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Validation transforms - NO augmentation\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SlizffYdbPgt"
      },
      "outputs": [],
      "source": [
        "class GemstoneDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[label_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TOjzQmPYbe61"
      },
      "outputs": [],
      "source": [
        "class GemstoneClassifierResnet101(nn.Module):\n",
        "    def __init__(self, size_inner=128, droprate=0.2, num_classes=87):\n",
        "        super(GemstoneClassifierResnet101, self).__init__()\n",
        "\n",
        "        # Load pre-trained Resnet101\n",
        "        modules = list(models.resnet101(weights='DEFAULT').children())[:-2]\n",
        "        self.base_model = nn.Sequential(*modules)\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.inner = nn.Linear(2048, size_inner)  # New inner layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(droprate)  # Add dropout\n",
        "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.inner(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sTIBJ9cBbjEd"
      },
      "outputs": [],
      "source": [
        "def make_model(learning_rate=0.001, size_inner=128, droprate=0.2):\n",
        "    model = GemstoneClassifierResnet101(droprate=droprate, size_inner=size_inner, num_classes=87)\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    return model, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4-UzsrjDblRd"
      },
      "outputs": [],
      "source": [
        "def download_and_rename_dataset(url, destination_filename):\n",
        "    try:\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "            with open(destination_filename, 'wb') as f:\n",
        "                shutil.copyfileobj(r.raw, f)\n",
        "        print(f\"Successfully downloaded and renamed file to: {os.path.abspath(destination_filename)}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred during download: {e}\")\n",
        "    except IOError as e:\n",
        "        print(f\"An error occurred while saving the file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bpiOJDkZbnRd"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    data_url = 'https://www.kaggle.com/api/v1/datasets/download/lsind18/gemstones-images'\n",
        "    new_name = 'gemstones_images.zip'\n",
        "\n",
        "    download_and_rename_dataset(data_url, new_name)\n",
        "\n",
        "    with zipfile.ZipFile(new_name, 'r') as zip_ref:\n",
        "        # Extract all contents to the specified directory\n",
        "        # If files already exist in './dataset', they will be overwritten\n",
        "        zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Rp_KRsTBbpks"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device, enable_checkout=False):\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    accuracy_progress = []\n",
        "    loss_progress = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # --- Training phase ---\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # --- Validation phase ---\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # Calculate Generalization Gap (Overfitting Measure)\n",
        "        # A smaller gap means less overfitting.\n",
        "        current_gap = abs(train_acc - val_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Gap: {current_gap:.4f}')\n",
        "\n",
        "        # --- Balanced Checkpointing Logic ---\n",
        "        # We save if:\n",
        "        # 1. We hit a new high in validation accuracy AND the gap is reasonable (e.g., < 10%)\n",
        "        # 2. OR it's the best balance of accuracy and gap we've seen yet.\n",
        "\n",
        "        if enable_checkout:\n",
        "            # Definition of \"Best\": High accuracy AND low gap\n",
        "            # You can adjust the 0.1 (10%) threshold based on your needs\n",
        "            is_best_acc = val_acc > best_val_accuracy\n",
        "            is_low_overfit = current_gap < 0.10\n",
        "\n",
        "            if is_best_acc and is_low_overfit:\n",
        "                best_val_accuracy = val_acc\n",
        "                checkpoint_path = f'gemstone_classifier_model_ep{epoch+1}_acc{val_acc:.3f}_gap{current_gap:.3f}.pth'\n",
        "                torch.save(model.state_dict(), checkpoint_path)\n",
        "                print(f'--> Best model saved (High Acc & Low Overfit)')\n",
        "\n",
        "        accuracy_progress.append((train_acc, val_acc))\n",
        "        loss_progress.append((train_loss, val_loss))\n",
        "\n",
        "    return best_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5JujQLBvbtEd"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    num_epochs = 10\n",
        "\n",
        "    # the best learning_rate\n",
        "    learning_rate = 0.001\n",
        "    # the best size_inner\n",
        "    size_inner = 128\n",
        "    # The best drop rate\n",
        "    droprate = 0.2\n",
        "\n",
        "    train_dataset = GemstoneDataset(\n",
        "        data_dir='./dataset/train',\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    val_dataset = GemstoneDataset(\n",
        "        data_dir='./dataset/test',\n",
        "        transform=val_transforms\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    model, optimizer = make_model(\n",
        "        learning_rate=learning_rate,\n",
        "        size_inner=size_inner,\n",
        "        droprate=droprate,\n",
        "    )\n",
        "\n",
        "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device, enable_checkout=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c2_DbVsRfMJc"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(filename):\n",
        "    # Search for 'acc' followed by digits and a decimal\n",
        "    match = re.search(r\"acc(\\d+\\.\\d+)\", filename)\n",
        "    return float(match.group(1)) if match else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U8BIgbuveZJc"
      },
      "outputs": [],
      "source": [
        "def load_best_model():\n",
        "    # Load the best saved model\n",
        "    model_list = glob.glob(f'gemstone_classifier_model_ep*.pth')\n",
        "    best_model = max(model_list, key=get_accuracy)\n",
        "\n",
        "    print(f\"Loading best model: {best_model}\")\n",
        "\n",
        "    model = GemstoneClassifierResnet101()\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C-FC5o7rbwvc"
      },
      "outputs": [],
      "source": [
        "def export_to_onnx(model):\n",
        "    # Create dummy input\n",
        "    dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
        "\n",
        "    # Export to ONNX\n",
        "    onnx_path = \"./gemstone_classifier_resnet101.onnx\"\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        verbose=True,\n",
        "        input_names=['input'],\n",
        "        output_names=['output'],\n",
        "        dynamic_axes={\n",
        "            'input': {0: 'batch_size'},\n",
        "            'output': {0: 'batch_size'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Model exported to {onnx_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "ZAE9LL8Ob0bk",
        "outputId": "47191c3f-48e7-4f80-8519-0d793e0693b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully downloaded and renamed file to: /content/gemstones_images.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 171M/171M [00:00<00:00, 193MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Acc: 0.1509 | Val Acc: 0.3361 | Gap: 0.1852\n",
            "Epoch 2/10 | Train Acc: 0.4051 | Val Acc: 0.4959 | Gap: 0.0908\n",
            "--> Best model saved (High Acc & Low Overfit)\n",
            "Epoch 3/10 | Train Acc: 0.5368 | Val Acc: 0.6116 | Gap: 0.0748\n",
            "--> Best model saved (High Acc & Low Overfit)\n",
            "Epoch 4/10 | Train Acc: 0.6282 | Val Acc: 0.6253 | Gap: 0.0028\n",
            "--> Best model saved (High Acc & Low Overfit)\n",
            "Epoch 5/10 | Train Acc: 0.6716 | Val Acc: 0.6198 | Gap: 0.0517\n",
            "Epoch 6/10 | Train Acc: 0.7132 | Val Acc: 0.6887 | Gap: 0.0245\n",
            "--> Best model saved (High Acc & Low Overfit)\n",
            "Epoch 7/10 | Train Acc: 0.7283 | Val Acc: 0.6832 | Gap: 0.0451\n",
            "Epoch 8/10 | Train Acc: 0.7504 | Val Acc: 0.7025 | Gap: 0.0479\n",
            "--> Best model saved (High Acc & Low Overfit)\n",
            "Epoch 9/10 | Train Acc: 0.7882 | Val Acc: 0.6997 | Gap: 0.0884\n",
            "Epoch 10/10 | Train Acc: 0.7987 | Val Acc: 0.6997 | Gap: 0.0989\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1002437142.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexport_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-540939785.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Load the best saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*{best_val_accuracy}*.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGemstoneClassifierResnet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "load_data()\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOVHaQlkfvzF",
        "outputId": "264f715f-80ab-4d19-90eb-424e4fb78ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model: gemstone_classifier_model_ep8_acc0.702_gap0.048.pth\n"
          ]
        }
      ],
      "source": [
        "model = load_best_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08cvjFSfzoU",
        "outputId": "0f7559b9-801f-478f-d2cb-0164808f3517"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1372104282.py:8: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `GemstoneClassifierResnet101([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `GemstoneClassifierResnet101([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 209 of general pattern rewrite rules.\n",
            "Model exported to ./models/gemstone_classifier_resnet101.onnx\n"
          ]
        }
      ],
      "source": [
        "export_to_onnx(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMfi2tGffw3l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
